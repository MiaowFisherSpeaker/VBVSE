{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b8a10b",
   "metadata": {},
   "source": [
    "# 对分词的探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-zh-v1.5')\n",
    "model = AutoModel.from_pretrained('BAAI/bge-large-zh-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42ba6ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['近日',\n",
       " '有',\n",
       " '媒体报道',\n",
       " '称',\n",
       " '中国',\n",
       " '科学家',\n",
       " '在',\n",
       " '南极',\n",
       " '发现',\n",
       " '了',\n",
       " '一种',\n",
       " '新型',\n",
       " '细菌',\n",
       " '这种',\n",
       " '细菌',\n",
       " '能够',\n",
       " '在',\n",
       " '零下',\n",
       " '20',\n",
       " '度',\n",
       " '的',\n",
       " '极端',\n",
       " '环境',\n",
       " '下',\n",
       " '生存']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "sentence = \"近日，有媒体报道称，中国科学家在南极发现了一种新型细菌，这种细菌能够在零下20度的极端环境下生存。\"\n",
    "# 分词，然后去掉标点\n",
    "tokens = jieba.lcut(sentence)\n",
    "tokens1 = tokens\n",
    "tokens = [re.sub(r'[^\\w\\s]', '', token) for token in tokens if re.sub(r'[^\\w\\s]', '', token)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa63eb6",
   "metadata": {},
   "source": [
    "###  分词去标点结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b44d9595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9940, -0.0095, -0.0290,  ..., -1.1730,  0.8795, -0.1893],\n",
       "        [ 0.5184, -0.4749,  0.0987,  ..., -0.4425,  0.0887, -0.0732],\n",
       "        [-0.3612, -0.1135, -0.4985,  ..., -0.7243,  0.3804, -0.2077],\n",
       "        ...,\n",
       "        [-0.3579,  0.6526,  0.0548,  ..., -0.1603,  0.5569, -1.0110],\n",
       "        [-0.0661,  0.1508, -0.0335,  ..., -1.0574, -0.0148, -0.8802],\n",
       "        [-0.6681, -0.3047, -0.1448,  ...,  0.3437,  0.3852,  0.0301]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "encoded_input  = tokenizer(tokens,padding=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_input)[0][:,0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7dc79",
   "metadata": {},
   "source": [
    "#### 试试评估模式省略的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25e906a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9940, -0.0095, -0.0290,  ..., -1.1730,  0.8795, -0.1893],\n",
       "        [ 0.5184, -0.4749,  0.0987,  ..., -0.4425,  0.0887, -0.0732],\n",
       "        [-0.3612, -0.1135, -0.4985,  ..., -0.7243,  0.3804, -0.2077],\n",
       "        ...,\n",
       "        [-0.3579,  0.6526,  0.0548,  ..., -0.1603,  0.5569, -1.0110],\n",
       "        [-0.0661,  0.1508, -0.0335,  ..., -1.0574, -0.0148, -0.8802],\n",
       "        [-0.6681, -0.3047, -0.1448,  ...,  0.3437,  0.3852,  0.0301]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output1 = model(**encoded_input)[0][:,0]\n",
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe954d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), torch.Size([25, 1024]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.all()==output1.all(),output1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02283c",
   "metadata": {},
   "source": [
    "<caption>说明没影响</caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4eafb",
   "metadata": {},
   "source": [
    "### 将分词去标点的结果作平均，从[p,embed_size]到[1,embed_size].\n",
    "注: 这里是对于一个完整caption的处理。\n",
    "p表示分词个数，对第0维度取平均\n",
    "但是如果传入的是列表 分析：batch_size个数据，目的得到[batch_size,1024]的张量。实际上每一个[1,1024]张量都是通过[pi,1024]平均得到的。而且很有可能pi≠pj,即不能扩充一维用于存放分词数量（作为维数）从而不能指定dim=(分词所在维数)以平均化。\n",
    "综上，此种情况个人认为的是一个caption一个caption处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "872a5e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0103,  0.0002, -0.0074,  ..., -0.0407,  0.0163, -0.0162]]),\n",
       " torch.Size([1, 1024]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output取平均值,后面均归一化也就是output[num]_1这个变量\n",
    "output1 = output1.mean(dim=0).unsqueeze(0)\n",
    "output1_1 = torch.nn.functional.normalize(output1, p=2, dim=1)\n",
    "\n",
    "output1_1,output1_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb0d07",
   "metadata": {},
   "source": [
    "不做任何处理的一句话，通过模型后再归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3afd6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0364, -0.0192,  0.0009,  ...,  0.0050,  0.0238,  0.0379]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input_raw =tokenizer(sentence,padding=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    output2 = model(**encoded_input_raw)[0][:,0]\n",
    "output2_1 = torch.nn.functional.normalize(output2, p=2, dim=1)\n",
    "output2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7fc47",
   "metadata": {},
   "source": [
    "### 分词后不去标点，通过模型后再归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03bce9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0087,  0.0044, -0.0003,  ..., -0.0461,  0.0128, -0.0220]]),\n",
       " torch.Size([1, 1024]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input1  = tokenizer(tokens1,padding=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    output3 = model(**encoded_input1)[0][:,0]\n",
    "output3 = output3.mean(dim=0).unsqueeze(0)\n",
    "output3_1 = torch.nn.functional.normalize(output3, p=2, dim=1)\n",
    "output3_1,output3_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74448a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检测是否归一化\n",
    "import numpy as np\n",
    "result3 = np.linalg.norm(output3_1,axis=1)\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edf5ae",
   "metadata": {},
   "source": [
    "### 引入一个完全无关的负样本(自认为，人工归类的)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9611198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0158, -0.0100, -0.0096,  ..., -0.0030,  0.0028,  0.0485]]),\n",
       " tensor([[ 0.0018, -0.0377, -0.0137,  ...,  0.0244, -0.0115,  0.0668]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这两个负样本是相似的\n",
    "input_F = \"在美国亚利桑那州，疯狂戴夫发明了一种金刚不坏的土豆，据说能够抵挡僵尸的攻击，向日葵开心极了\"\n",
    "input_F1 = \"在美国纽约，僵王博士发明了一种金刚不坏的土豆僵尸，据说能够抵挡植物的攻击，它开心极了\"\n",
    "\n",
    "encoded_input_F  = tokenizer(input_F,padding=True, return_tensors=\"pt\")\n",
    "encoded_input_F1  = tokenizer(input_F1,padding=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    output_F = model(**encoded_input_F)[0][:,0]\n",
    "    output_F1 = model(**encoded_input_F1)[0][:,0]\n",
    "output_F_1 = torch.nn.functional.normalize(output_F, p=2, dim=1)\n",
    "output_F1_1 = torch.nn.functional.normalize(output_F1, p=2, dim=1)\n",
    "output_F_1,output_F1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ef6593",
   "metadata": {},
   "source": [
    "### 计算3+1个向量的距离（余弦相似度以及欧氏距离）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "821a4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_similarity_and_distance(tensors:list, names:list):\n",
    "    num_tensors = len(tensors)\n",
    "    # 初始化余弦相似度和欧几里得距离矩阵\n",
    "    cosine_similarity_matrix = np.zeros((num_tensors, num_tensors))\n",
    "    euclidean_distance_matrix = np.zeros((num_tensors, num_tensors))\n",
    "\n",
    "    # 计算每对张量之间的余弦相似度和欧几里得距离\n",
    "    for i in range(num_tensors):\n",
    "        for j in range(num_tensors):\n",
    "            if i != j:  # 排除自身与自身的比较\n",
    "                cosine_similarity_matrix[i, j] = torch.nn.functional.cosine_similarity(tensors[i], tensors[j])\n",
    "                euclidean_distance_matrix[i, j] = torch.norm(tensors[i] - tensors[j])\n",
    "            else:  # 自身与自身的相似度设置为1，距离设置为0\n",
    "                cosine_similarity_matrix[i, j] = 1.0\n",
    "                euclidean_distance_matrix[i, j] = 0.0\n",
    "\n",
    "    # 创建余弦相似度表格\n",
    "    cosine_similarity_df = pd.DataFrame(cosine_similarity_matrix, index=names, columns=names)\n",
    "    # 创建欧几里得距离表格\n",
    "    euclidean_distance_df = pd.DataFrame(euclidean_distance_matrix, index=names, columns=names)\n",
    "\n",
    "    return cosine_similarity_df, euclidean_distance_df\n",
    "\n",
    "def find_nearest_tensors(cosine_similarity_df, euclidean_distance_df):\n",
    "    # 设置对角线（自己和自己）为nan\n",
    "    cosine_similarity_df.values[np.diag_indices_from(cosine_similarity_df)] = np.nan\n",
    "    euclidean_distance_df.values[np.diag_indices_from(euclidean_distance_df)] = np.nan\n",
    "    # 余弦相似度：找到每个张量最相似的张量（自身除外）\n",
    "    cosine_nearest = cosine_similarity_df.idxmax().rename(\"Cosine Nearest Tensor\")\n",
    "    # 欧几里得距离：找到每个张量最近的张量（自身除外）\n",
    "    euclidean_nearest = euclidean_distance_df.idxmin().rename(\"Euclidean Nearest Tensor\")\n",
    "\n",
    "    # 创建一个新的 DataFrame 来保存结果\n",
    "    nearest_tensors_df = pd.DataFrame({\n",
    "        'Cosine Nearest Tensor': cosine_nearest,\n",
    "        'Euclidean Nearest Tensor': euclidean_nearest\n",
    "    })\n",
    "    \n",
    "    # 计算排序，基于余弦相似度和欧几里得距离\n",
    "    cosine_similarity_ranking = cosine_similarity_df.rank(1, ascending=False)  # 余弦相似度越高，排名越前\n",
    "    euclidean_distance_ranking = euclidean_distance_df.rank(1)  # 欧几里得距离越小，排名越前\n",
    "\n",
    "    return nearest_tensors_df, cosine_similarity_ranking, euclidean_distance_ranking\n",
    "\n",
    "\n",
    "tensors = [output2_1,output1_1,output3_1,output_F_1,output_F1_1]\n",
    "names = [\"不做处理\",\"分词去标点\",\"分词不去标点\",\"负样本\",\"负样本的相似样本\"]\n",
    "c_df,e_df = calculate_similarity_and_distance(tensors,names)\n",
    "near_df,cs_df,es_df = find_nearest_tensors(c_df,e_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d67513d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>不做处理</th>\n",
       "      <th>分词去标点</th>\n",
       "      <th>分词不去标点</th>\n",
       "      <th>负样本</th>\n",
       "      <th>负样本的相似样本</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>不做处理</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469554</td>\n",
       "      <td>0.433262</td>\n",
       "      <td>0.360374</td>\n",
       "      <td>0.368029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词去标点</th>\n",
       "      <td>0.469554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990061</td>\n",
       "      <td>0.393847</td>\n",
       "      <td>0.401334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词不去标点</th>\n",
       "      <td>0.433262</td>\n",
       "      <td>0.990061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.380646</td>\n",
       "      <td>0.388923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本</th>\n",
       "      <td>0.360374</td>\n",
       "      <td>0.393847</td>\n",
       "      <td>0.380646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.787223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本的相似样本</th>\n",
       "      <td>0.368029</td>\n",
       "      <td>0.401334</td>\n",
       "      <td>0.388923</td>\n",
       "      <td>0.787223</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              不做处理     分词去标点    分词不去标点       负样本  负样本的相似样本\n",
       "不做处理           NaN  0.469554  0.433262  0.360374  0.368029\n",
       "分词去标点     0.469554       NaN  0.990061  0.393847  0.401334\n",
       "分词不去标点    0.433262  0.990061       NaN  0.380646  0.388923\n",
       "负样本       0.360374  0.393847  0.380646       NaN  0.787223\n",
       "负样本的相似样本  0.368029  0.401334  0.388923  0.787223       NaN"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 余弦相似度比较 越近越靠近1\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "245a26cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>不做处理</th>\n",
       "      <th>分词去标点</th>\n",
       "      <th>分词不去标点</th>\n",
       "      <th>负样本</th>\n",
       "      <th>负样本的相似样本</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>不做处理</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029996</td>\n",
       "      <td>1.064648</td>\n",
       "      <td>1.131040</td>\n",
       "      <td>1.124252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词去标点</th>\n",
       "      <td>1.029996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140988</td>\n",
       "      <td>1.101048</td>\n",
       "      <td>1.094226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词不去标点</th>\n",
       "      <td>1.064648</td>\n",
       "      <td>0.140988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.112972</td>\n",
       "      <td>1.105511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本</th>\n",
       "      <td>1.131040</td>\n",
       "      <td>1.101048</td>\n",
       "      <td>1.112972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.652345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本的相似样本</th>\n",
       "      <td>1.124252</td>\n",
       "      <td>1.094226</td>\n",
       "      <td>1.105511</td>\n",
       "      <td>0.652345</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              不做处理     分词去标点    分词不去标点       负样本  负样本的相似样本\n",
       "不做处理           NaN  1.029996  1.064648  1.131040  1.124252\n",
       "分词去标点     1.029996       NaN  0.140988  1.101048  1.094226\n",
       "分词不去标点    1.064648  0.140988       NaN  1.112972  1.105511\n",
       "负样本       1.131040  1.101048  1.112972       NaN  0.652345\n",
       "负样本的相似样本  1.124252  1.094226  1.105511  0.652345       NaN"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欧氏距离比较，越近越靠近0\n",
    "e_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6784c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Nearest Tensor</th>\n",
       "      <th>Euclidean Nearest Tensor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>不做处理</th>\n",
       "      <td>分词去标点</td>\n",
       "      <td>分词去标点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词去标点</th>\n",
       "      <td>分词不去标点</td>\n",
       "      <td>分词不去标点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词不去标点</th>\n",
       "      <td>分词去标点</td>\n",
       "      <td>分词去标点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本</th>\n",
       "      <td>负样本的相似样本</td>\n",
       "      <td>负样本的相似样本</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本的相似样本</th>\n",
       "      <td>负样本</td>\n",
       "      <td>负样本</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cosine Nearest Tensor Euclidean Nearest Tensor\n",
       "不做处理                     分词去标点                    分词去标点\n",
       "分词去标点                   分词不去标点                   分词不去标点\n",
       "分词不去标点                   分词去标点                    分词去标点\n",
       "负样本                   负样本的相似样本                 负样本的相似样本\n",
       "负样本的相似样本                   负样本                      负样本"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直观排序表示（最近的向量）\n",
    "near_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce1bc447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>不做处理</th>\n",
       "      <th>分词去标点</th>\n",
       "      <th>分词不去标点</th>\n",
       "      <th>负样本</th>\n",
       "      <th>负样本的相似样本</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>不做处理</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词去标点</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词不去标点</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本的相似样本</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          不做处理  分词去标点  分词不去标点  负样本  负样本的相似样本\n",
       "不做处理       NaN    1.0     2.0  4.0       3.0\n",
       "分词去标点      2.0    NaN     1.0  4.0       3.0\n",
       "分词不去标点     2.0    1.0     NaN  4.0       3.0\n",
       "负样本        4.0    2.0     3.0  NaN       1.0\n",
       "负样本的相似样本   4.0    2.0     3.0  1.0       NaN"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 余弦相似度比较排序\n",
    "cs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23678348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>不做处理</th>\n",
       "      <th>分词去标点</th>\n",
       "      <th>分词不去标点</th>\n",
       "      <th>负样本</th>\n",
       "      <th>负样本的相似样本</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>不做处理</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词去标点</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>分词不去标点</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>负样本的相似样本</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          不做处理  分词去标点  分词不去标点  负样本  负样本的相似样本\n",
       "不做处理       NaN    1.0     2.0  4.0       3.0\n",
       "分词去标点      2.0    NaN     1.0  4.0       3.0\n",
       "分词不去标点     2.0    1.0     NaN  4.0       3.0\n",
       "负样本        4.0    2.0     3.0  NaN       1.0\n",
       "负样本的相似样本   4.0    2.0     3.0  1.0       NaN"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欧氏距离比较排序\n",
    "es_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
